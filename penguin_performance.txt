Base DT Model:
(A) Model Description:
Base DT Model with hyperparameters: {'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'random_state': None, 'splitter': 'best'}
(B) Confusion Matrix:
[[31  0  0]
 [ 0 13  0]
 [ 0  0 23]]
Precision Scores: [1. 1. 1.]
Recall Scores: [1. 1. 1.]
F1 Scores: [1. 1. 1.]
(C) Precision, Recall, and F1:
              precision    recall  f1-score   support

      Adelie       1.00      1.00      1.00        31
   Chinstrap       1.00      1.00      1.00        13
      Gentoo       1.00      1.00      1.00        23

    accuracy                           1.00        67
   macro avg       1.00      1.00      1.00        67
weighted avg       1.00      1.00      1.00        67

(D) Accuracy: 1.0
(D) Macro-average F1: 1.0
(D) Weighted-average F1: 1.0
--------------------
Top DT Model:
(A) Model Description:
Top DT Model with hyperparameters: {'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': 5, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'random_state': None, 'splitter': 'best'}
(B) Confusion Matrix:
[[31  0  0]
 [ 0 13  0]
 [ 0  0 23]]
Precision Scores: [1. 1. 1.]
Recall Scores: [1. 1. 1.]
F1 Scores: [1. 1. 1.]
(C) Precision, Recall, and F1:
              precision    recall  f1-score   support

      Adelie       1.00      1.00      1.00        31
   Chinstrap       1.00      1.00      1.00        13
      Gentoo       1.00      1.00      1.00        23

    accuracy                           1.00        67
   macro avg       1.00      1.00      1.00        67
weighted avg       1.00      1.00      1.00        67

(D) Accuracy: 1.0
(D) Macro-average F1: 1.0
(D) Weighted-average F1: 1.0
--------------------
Base MLP Model:
(A) Model Description:
Base MLP Model with hyperparameters: {'activation': 'relu', 'alpha': 0.0001, 'batch_size': 'auto', 'beta_1': 0.9, 'beta_2': 0.999, 'early_stopping': False, 'epsilon': 1e-08, 'hidden_layer_sizes': (100,), 'learning_rate': 'constant', 'learning_rate_init': 0.001, 'max_fun': 15000, 'max_iter': 1000, 'momentum': 0.9, 'n_iter_no_change': 10, 'nesterovs_momentum': True, 'power_t': 0.5, 'random_state': 42, 'shuffle': True, 'solver': 'adam', 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': False, 'warm_start': False}
(B) Confusion Matrix:
[[28  1  2]
 [10  3  0]
 [ 6  0 17]]
Precision Scores: [0.63636364 0.75       0.89473684]
Recall Scores: [0.90322581 0.23076923 0.73913043]
F1 Scores: [0.74666667 0.35294118 0.80952381]
(C) Precision, Recall, and F1:
              precision    recall  f1-score   support

      Adelie       0.64      0.90      0.75        31
   Chinstrap       0.75      0.23      0.35        13
      Gentoo       0.89      0.74      0.81        23

    accuracy                           0.72        67
   macro avg       0.76      0.62      0.64        67
weighted avg       0.75      0.72      0.69        67

(D) Accuracy: 0.7164179104477612
(D) Macro-average F1: 0.6363772175536881
(D) Weighted-average F1: 0.6918499937288348
--------------------
Top MLP Model:
(A) Model Description:
Top MLP Model with hyperparameters: {'activation': 'tanh', 'alpha': 0.0001, 'batch_size': 'auto', 'beta_1': 0.9, 'beta_2': 0.999, 'early_stopping': False, 'epsilon': 1e-08, 'hidden_layer_sizes': (30, 50), 'learning_rate': 'constant', 'learning_rate_init': 0.001, 'max_fun': 15000, 'max_iter': 1000, 'momentum': 0.9, 'n_iter_no_change': 10, 'nesterovs_momentum': True, 'power_t': 0.5, 'random_state': None, 'shuffle': True, 'solver': 'adam', 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': False, 'warm_start': False}
(B) Confusion Matrix:
[[31  0  0]
 [13  0  0]
 [23  0  0]]
Precision Scores: [0.46268657 1.         1.        ]
Recall Scores: [1. 0. 0.]
F1 Scores: [0.63265306 0.         0.        ]
(C) Precision, Recall, and F1:
              precision    recall  f1-score   support

      Adelie       0.46      1.00      0.63        31
   Chinstrap       1.00      0.00      0.00        13
      Gentoo       1.00      0.00      0.00        23

    accuracy                           0.46        67
   macro avg       0.82      0.33      0.21        67
weighted avg       0.75      0.46      0.29        67

(D) Accuracy: 0.4626865671641791
(D) Macro-average F1: 0.2108843537414966
(D) Weighted-average F1: 0.29272007310386844
--------------------
Base DT Model:
(A) Model Description:
Base DT Model with hyperparameters: {'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'random_state': None, 'splitter': 'best'}
(B) Confusion Matrix:
[[31  0  0]
 [ 0 13  0]
 [ 0  0 23]]
Precision Scores: [1. 1. 1.]
Recall Scores: [1. 1. 1.]
F1 Scores: [1. 1. 1.]
(C) Precision, Recall, and F1:
              precision    recall  f1-score   support

      Adelie       1.00      1.00      1.00        31
   Chinstrap       1.00      1.00      1.00        13
      Gentoo       1.00      1.00      1.00        23

    accuracy                           1.00        67
   macro avg       1.00      1.00      1.00        67
weighted avg       1.00      1.00      1.00        67

(D) Accuracy: 1.0
(D) Macro-average F1: 1.0
(D) Weighted-average F1: 1.0
--------------------
Top DT Model:
(A) Model Description:
Top DT Model with hyperparameters: {'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': 5, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'random_state': None, 'splitter': 'best'}
(B) Confusion Matrix:
[[31  0  0]
 [ 0 13  0]
 [ 0  0 23]]
Precision Scores: [1. 1. 1.]
Recall Scores: [1. 1. 1.]
F1 Scores: [1. 1. 1.]
(C) Precision, Recall, and F1:
              precision    recall  f1-score   support

      Adelie       1.00      1.00      1.00        31
   Chinstrap       1.00      1.00      1.00        13
      Gentoo       1.00      1.00      1.00        23

    accuracy                           1.00        67
   macro avg       1.00      1.00      1.00        67
weighted avg       1.00      1.00      1.00        67

(D) Accuracy: 1.0
(D) Macro-average F1: 1.0
(D) Weighted-average F1: 1.0
--------------------
Base MLP Model:
(A) Model Description:
Base MLP Model with hyperparameters: {'activation': 'relu', 'alpha': 0.0001, 'batch_size': 'auto', 'beta_1': 0.9, 'beta_2': 0.999, 'early_stopping': False, 'epsilon': 1e-08, 'hidden_layer_sizes': (100,), 'learning_rate': 'constant', 'learning_rate_init': 0.001, 'max_fun': 15000, 'max_iter': 1000, 'momentum': 0.9, 'n_iter_no_change': 10, 'nesterovs_momentum': True, 'power_t': 0.5, 'random_state': 42, 'shuffle': True, 'solver': 'adam', 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': False, 'warm_start': False}
(B) Confusion Matrix:
[[28  1  2]
 [10  3  0]
 [ 6  0 17]]
Precision Scores: [0.63636364 0.75       0.89473684]
Recall Scores: [0.90322581 0.23076923 0.73913043]
F1 Scores: [0.74666667 0.35294118 0.80952381]
(C) Precision, Recall, and F1:
              precision    recall  f1-score   support

      Adelie       0.64      0.90      0.75        31
   Chinstrap       0.75      0.23      0.35        13
      Gentoo       0.89      0.74      0.81        23

    accuracy                           0.72        67
   macro avg       0.76      0.62      0.64        67
weighted avg       0.75      0.72      0.69        67

(D) Accuracy: 0.7164179104477612
(D) Macro-average F1: 0.6363772175536881
(D) Weighted-average F1: 0.6918499937288348
--------------------
Top MLP Model:
(A) Model Description:
Top MLP Model with hyperparameters: {'activation': 'tanh', 'alpha': 0.0001, 'batch_size': 'auto', 'beta_1': 0.9, 'beta_2': 0.999, 'early_stopping': False, 'epsilon': 1e-08, 'hidden_layer_sizes': (30, 50), 'learning_rate': 'constant', 'learning_rate_init': 0.001, 'max_fun': 15000, 'max_iter': 1000, 'momentum': 0.9, 'n_iter_no_change': 10, 'nesterovs_momentum': True, 'power_t': 0.5, 'random_state': None, 'shuffle': True, 'solver': 'adam', 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': False, 'warm_start': False}
(B) Confusion Matrix:
[[31  0  0]
 [13  0  0]
 [23  0  0]]
Precision Scores: [0.46268657 1.         1.        ]
Recall Scores: [1. 0. 0.]
F1 Scores: [0.63265306 0.         0.        ]
(C) Precision, Recall, and F1:
              precision    recall  f1-score   support

      Adelie       0.46      1.00      0.63        31
   Chinstrap       1.00      0.00      0.00        13
      Gentoo       1.00      0.00      0.00        23

    accuracy                           0.46        67
   macro avg       0.82      0.33      0.21        67
weighted avg       0.75      0.46      0.29        67

(D) Accuracy: 0.4626865671641791
(D) Macro-average F1: 0.2108843537414966
(D) Weighted-average F1: 0.29272007310386844
--------------------
Base DT Model:
(A) Model Description:
Base DT Model with hyperparameters: {'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'random_state': None, 'splitter': 'best'}
(B) Confusion Matrix:
[[31  0  0]
 [ 0 13  0]
 [ 0  0 23]]
Precision Scores: [1. 1. 1.]
Recall Scores: [1. 1. 1.]
F1 Scores: [1. 1. 1.]
(C) Precision, Recall, and F1:
              precision    recall  f1-score   support

      Adelie       1.00      1.00      1.00        31
   Chinstrap       1.00      1.00      1.00        13
      Gentoo       1.00      1.00      1.00        23

    accuracy                           1.00        67
   macro avg       1.00      1.00      1.00        67
weighted avg       1.00      1.00      1.00        67

(D) Accuracy: 1.0
(D) Macro-average F1: 1.0
(D) Weighted-average F1: 1.0
--------------------
Top DT Model:
(A) Model Description:
Top DT Model with hyperparameters: {'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': 5, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'random_state': None, 'splitter': 'best'}
(B) Confusion Matrix:
[[31  0  0]
 [ 0 13  0]
 [ 0  0 23]]
Precision Scores: [1. 1. 1.]
Recall Scores: [1. 1. 1.]
F1 Scores: [1. 1. 1.]
(C) Precision, Recall, and F1:
              precision    recall  f1-score   support

      Adelie       1.00      1.00      1.00        31
   Chinstrap       1.00      1.00      1.00        13
      Gentoo       1.00      1.00      1.00        23

    accuracy                           1.00        67
   macro avg       1.00      1.00      1.00        67
weighted avg       1.00      1.00      1.00        67

(D) Accuracy: 1.0
(D) Macro-average F1: 1.0
(D) Weighted-average F1: 1.0
--------------------
Base MLP Model:
(A) Model Description:
Base MLP Model with hyperparameters: {'activation': 'relu', 'alpha': 0.0001, 'batch_size': 'auto', 'beta_1': 0.9, 'beta_2': 0.999, 'early_stopping': False, 'epsilon': 1e-08, 'hidden_layer_sizes': (100,), 'learning_rate': 'constant', 'learning_rate_init': 0.001, 'max_fun': 15000, 'max_iter': 1000, 'momentum': 0.9, 'n_iter_no_change': 10, 'nesterovs_momentum': True, 'power_t': 0.5, 'random_state': 42, 'shuffle': True, 'solver': 'adam', 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': False, 'warm_start': False}
(B) Confusion Matrix:
[[28  1  2]
 [10  3  0]
 [ 6  0 17]]
Precision Scores: [0.63636364 0.75       0.89473684]
Recall Scores: [0.90322581 0.23076923 0.73913043]
F1 Scores: [0.74666667 0.35294118 0.80952381]
(C) Precision, Recall, and F1:
              precision    recall  f1-score   support

      Adelie       0.64      0.90      0.75        31
   Chinstrap       0.75      0.23      0.35        13
      Gentoo       0.89      0.74      0.81        23

    accuracy                           0.72        67
   macro avg       0.76      0.62      0.64        67
weighted avg       0.75      0.72      0.69        67

(D) Accuracy: 0.7164179104477612
(D) Macro-average F1: 0.6363772175536881
(D) Weighted-average F1: 0.6918499937288348
--------------------
Top MLP Model:
(A) Model Description:
Top MLP Model with hyperparameters: {'activation': 'tanh', 'alpha': 0.0001, 'batch_size': 'auto', 'beta_1': 0.9, 'beta_2': 0.999, 'early_stopping': False, 'epsilon': 1e-08, 'hidden_layer_sizes': (30, 50), 'learning_rate': 'constant', 'learning_rate_init': 0.001, 'max_fun': 15000, 'max_iter': 1000, 'momentum': 0.9, 'n_iter_no_change': 10, 'nesterovs_momentum': True, 'power_t': 0.5, 'random_state': None, 'shuffle': True, 'solver': 'adam', 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': False, 'warm_start': False}
(B) Confusion Matrix:
[[31  0  0]
 [13  0  0]
 [23  0  0]]
Precision Scores: [0.46268657 1.         1.        ]
Recall Scores: [1. 0. 0.]
F1 Scores: [0.63265306 0.         0.        ]
(C) Precision, Recall, and F1:
              precision    recall  f1-score   support

      Adelie       0.46      1.00      0.63        31
   Chinstrap       1.00      0.00      0.00        13
      Gentoo       1.00      0.00      0.00        23

    accuracy                           0.46        67
   macro avg       0.82      0.33      0.21        67
weighted avg       0.75      0.46      0.29        67

(D) Accuracy: 0.4626865671641791
(D) Macro-average F1: 0.2108843537414966
(D) Weighted-average F1: 0.29272007310386844
--------------------
Base DT Model:
(A) Model Description:
Base DT Model with hyperparameters: {'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'random_state': None, 'splitter': 'best'}
(B) Confusion Matrix:
[[30  1  0]
 [ 0 13  0]
 [ 0  0 23]]
Precision Scores: [1.         0.92857143 1.        ]
Recall Scores: [0.96774194 1.         1.        ]
F1 Scores: [0.98360656 0.96296296 1.        ]
(C) Precision, Recall, and F1:
              precision    recall  f1-score   support

      Adelie       1.00      0.97      0.98        31
   Chinstrap       0.93      1.00      0.96        13
      Gentoo       1.00      1.00      1.00        23

    accuracy                           0.99        67
   macro avg       0.98      0.99      0.98        67
weighted avg       0.99      0.99      0.99        67

(D) Accuracy: 0.9850746268656716
(D) Macro-average F1: 0.9821898401133374
(D) Weighted-average F1: 0.9852286835404036
--------------------
Top DT Model:
(A) Model Description:
Top DT Model with hyperparameters: {'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': 5, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'random_state': None, 'splitter': 'best'}
(B) Confusion Matrix:
[[31  0  0]
 [ 0 13  0]
 [ 0  0 23]]
Precision Scores: [1. 1. 1.]
Recall Scores: [1. 1. 1.]
F1 Scores: [1. 1. 1.]
(C) Precision, Recall, and F1:
              precision    recall  f1-score   support

      Adelie       1.00      1.00      1.00        31
   Chinstrap       1.00      1.00      1.00        13
      Gentoo       1.00      1.00      1.00        23

    accuracy                           1.00        67
   macro avg       1.00      1.00      1.00        67
weighted avg       1.00      1.00      1.00        67

(D) Accuracy: 1.0
(D) Macro-average F1: 1.0
(D) Weighted-average F1: 1.0
--------------------
Base MLP Model:
(A) Model Description:
Base MLP Model with hyperparameters: {'activation': 'relu', 'alpha': 0.0001, 'batch_size': 'auto', 'beta_1': 0.9, 'beta_2': 0.999, 'early_stopping': False, 'epsilon': 1e-08, 'hidden_layer_sizes': (100,), 'learning_rate': 'constant', 'learning_rate_init': 0.001, 'max_fun': 15000, 'max_iter': 1000, 'momentum': 0.9, 'n_iter_no_change': 10, 'nesterovs_momentum': True, 'power_t': 0.5, 'random_state': 42, 'shuffle': True, 'solver': 'adam', 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': False, 'warm_start': False}
(B) Confusion Matrix:
[[28  1  2]
 [10  3  0]
 [ 6  0 17]]
Precision Scores: [0.63636364 0.75       0.89473684]
Recall Scores: [0.90322581 0.23076923 0.73913043]
F1 Scores: [0.74666667 0.35294118 0.80952381]
(C) Precision, Recall, and F1:
              precision    recall  f1-score   support

      Adelie       0.64      0.90      0.75        31
   Chinstrap       0.75      0.23      0.35        13
      Gentoo       0.89      0.74      0.81        23

    accuracy                           0.72        67
   macro avg       0.76      0.62      0.64        67
weighted avg       0.75      0.72      0.69        67

(D) Accuracy: 0.7164179104477612
(D) Macro-average F1: 0.6363772175536881
(D) Weighted-average F1: 0.6918499937288348
--------------------
Top MLP Model:
(A) Model Description:
Top MLP Model with hyperparameters: {'activation': 'tanh', 'alpha': 0.0001, 'batch_size': 'auto', 'beta_1': 0.9, 'beta_2': 0.999, 'early_stopping': False, 'epsilon': 1e-08, 'hidden_layer_sizes': (30, 50), 'learning_rate': 'constant', 'learning_rate_init': 0.001, 'max_fun': 15000, 'max_iter': 1000, 'momentum': 0.9, 'n_iter_no_change': 10, 'nesterovs_momentum': True, 'power_t': 0.5, 'random_state': None, 'shuffle': True, 'solver': 'adam', 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': False, 'warm_start': False}
(B) Confusion Matrix:
[[31  0  0]
 [13  0  0]
 [23  0  0]]
Precision Scores: [0.46268657 1.         1.        ]
Recall Scores: [1. 0. 0.]
F1 Scores: [0.63265306 0.         0.        ]
(C) Precision, Recall, and F1:
              precision    recall  f1-score   support

      Adelie       0.46      1.00      0.63        31
   Chinstrap       1.00      0.00      0.00        13
      Gentoo       1.00      0.00      0.00        23

    accuracy                           0.46        67
   macro avg       0.82      0.33      0.21        67
weighted avg       0.75      0.46      0.29        67

(D) Accuracy: 0.4626865671641791
(D) Macro-average F1: 0.2108843537414966
(D) Weighted-average F1: 0.29272007310386844
--------------------
Base DT Model:
(A) Model Description:
Base DT Model with hyperparameters: {'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'random_state': None, 'splitter': 'best'}
(B) Confusion Matrix:
[[30  1  0]
 [ 0 13  0]
 [ 0  0 23]]
Precision Scores: [1.         0.92857143 1.        ]
Recall Scores: [0.96774194 1.         1.        ]
F1 Scores: [0.98360656 0.96296296 1.        ]
(C) Precision, Recall, and F1:
              precision    recall  f1-score   support

      Adelie       1.00      0.97      0.98        31
   Chinstrap       0.93      1.00      0.96        13
      Gentoo       1.00      1.00      1.00        23

    accuracy                           0.99        67
   macro avg       0.98      0.99      0.98        67
weighted avg       0.99      0.99      0.99        67

(D) Accuracy: 0.9850746268656716
(D) Macro-average F1: 0.9821898401133374
(D) Weighted-average F1: 0.9852286835404036
--------------------
Top DT Model:
(A) Model Description:
Top DT Model with hyperparameters: {'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': 5, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'random_state': None, 'splitter': 'best'}
(B) Confusion Matrix:
[[31  0  0]
 [ 0 13  0]
 [ 0  0 23]]
Precision Scores: [1. 1. 1.]
Recall Scores: [1. 1. 1.]
F1 Scores: [1. 1. 1.]
(C) Precision, Recall, and F1:
              precision    recall  f1-score   support

      Adelie       1.00      1.00      1.00        31
   Chinstrap       1.00      1.00      1.00        13
      Gentoo       1.00      1.00      1.00        23

    accuracy                           1.00        67
   macro avg       1.00      1.00      1.00        67
weighted avg       1.00      1.00      1.00        67

(D) Accuracy: 1.0
(D) Macro-average F1: 1.0
(D) Weighted-average F1: 1.0
--------------------
Base MLP Model:
(A) Model Description:
Base MLP Model with hyperparameters: {'activation': 'relu', 'alpha': 0.0001, 'batch_size': 'auto', 'beta_1': 0.9, 'beta_2': 0.999, 'early_stopping': False, 'epsilon': 1e-08, 'hidden_layer_sizes': (100,), 'learning_rate': 'constant', 'learning_rate_init': 0.001, 'max_fun': 15000, 'max_iter': 1000, 'momentum': 0.9, 'n_iter_no_change': 10, 'nesterovs_momentum': True, 'power_t': 0.5, 'random_state': 42, 'shuffle': True, 'solver': 'adam', 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': False, 'warm_start': False}
(B) Confusion Matrix:
[[28  1  2]
 [10  3  0]
 [ 6  0 17]]
Precision Scores: [0.63636364 0.75       0.89473684]
Recall Scores: [0.90322581 0.23076923 0.73913043]
F1 Scores: [0.74666667 0.35294118 0.80952381]
(C) Precision, Recall, and F1:
              precision    recall  f1-score   support

      Adelie       0.64      0.90      0.75        31
   Chinstrap       0.75      0.23      0.35        13
      Gentoo       0.89      0.74      0.81        23

    accuracy                           0.72        67
   macro avg       0.76      0.62      0.64        67
weighted avg       0.75      0.72      0.69        67

(D) Accuracy: 0.7164179104477612
(D) Macro-average F1: 0.6363772175536881
(D) Weighted-average F1: 0.6918499937288348
--------------------
Top MLP Model:
(A) Model Description:
Top MLP Model with hyperparameters: {'activation': 'tanh', 'alpha': 0.0001, 'batch_size': 'auto', 'beta_1': 0.9, 'beta_2': 0.999, 'early_stopping': False, 'epsilon': 1e-08, 'hidden_layer_sizes': (30, 50), 'learning_rate': 'constant', 'learning_rate_init': 0.001, 'max_fun': 15000, 'max_iter': 1000, 'momentum': 0.9, 'n_iter_no_change': 10, 'nesterovs_momentum': True, 'power_t': 0.5, 'random_state': None, 'shuffle': True, 'solver': 'adam', 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': False, 'warm_start': False}
(B) Confusion Matrix:
[[27  0  4]
 [13  0  0]
 [ 1  0 22]]
Precision Scores: [0.65853659 1.         0.84615385]
Recall Scores: [0.87096774 0.         0.95652174]
F1 Scores: [0.75       0.         0.89795918]
(C) Precision, Recall, and F1:
              precision    recall  f1-score   support

      Adelie       0.66      0.87      0.75        31
   Chinstrap       1.00      0.00      0.00        13
      Gentoo       0.85      0.96      0.90        23

    accuracy                           0.73        67
   macro avg       0.83      0.61      0.55        67
weighted avg       0.79      0.73      0.66        67

(D) Accuracy: 0.7313432835820896
(D) Macro-average F1: 0.5493197278911565
(D) Weighted-average F1: 0.6552695705147731
--------------------
